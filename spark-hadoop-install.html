<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="generator" content="pandoc">
    <title>Software Carpentry: 데이터 과학</title>
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" type="text/css" href="css/bootstrap/bootstrap.css" />
    <link rel="stylesheet" type="text/css" href="css/bootstrap/bootstrap-theme.css" />
    <link rel="stylesheet" type="text/css" href="css/swc.css" />
    <link rel="alternate" type="application/rss+xml" title="Software Carpentry Blog" href="http://software-carpentry.org/feed.xml"/>
    <meta charset="UTF-8" />
    <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="https://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    
      ga('create', 'UA-59802572-19', 'auto');
      ga('send', 'pageview');
    
    </script>
  </head>
  <body class="lesson">
    <div class="container card">
      <div class="banner">
        <a href="http://software-carpentry.org" title="Software Carpentry">
          <img alt="Software Carpentry banner" src="img/software-carpentry-banner.png" />
        </a>
      </div>
      <article>
      <div class="row">
        <div class="col-md-10 col-md-offset-1">
                    <a href="index.html"><h1 class="title">데이터 과학</h1></a>
          <h2 class="subtitle">SparkR 설치</h2>
          <section class="objectives panel panel-warning">
<div class="panel-heading">
<h3 id="학습-목표"><span class="glyphicon glyphicon-certificate"></span>학습 목표</h3>
</div>
<div class="panel-body">
<ul>
<li>R 기반 스파크-하둡 플랫폼을 설치한다.</li>
<li>가상컴퓨터, 자바, 하둡-스파크, R를 왜 설치하는지 이해한다.</li>
<li>SparkR로 빅데이터 헬로 월드를 찍어본다.</li>
</ul>
</div>
</section>
<h3 id="r-기반-스파크-하둡-플랫폼-apache-spark-ubuntu">1. R 기반 스파크-하둡 플랫폼 <a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></h3>
<p><img src="fig/sparkR-arch.png" alt="R 기반 스파크-하둡 아키텍처" width="70%"></p>
<p>리눅스가 설치된 컴퓨터가 있다면 바로 R 기반 빅데이터 처리 스파크-하둡 툴체인을 구축할 수 있지만, 윈도우 기반에서 가상컴퓨터를 무리없이 돌릴 수 있는 하드웨어가 갖추어진 경우 다음 절차에 따라 설치작업을 완료하면 R 기반 스파크-하둡 플랫폼이 준비된다.</p>
<ol style="list-style-type: decimal">
<li>부랑자(Vagrant)를 사용하여 우분투 운영체제가 설치된 리눅스 컴퓨터를 생성시킨다.</li>
<li>리눅스 컴퓨터 위에 하둡을 설치하기 위한 전제조건으로 자바를 설치한다.</li>
<li>하둡을 설치해야 하는데, 아파치 스파크를 설치하는 경우 자동으로 포함되어 있다.</li>
<li>아파치 스파크를 설치한다. (하둡도 함께 내장된 버젼을 사용하면 편리하다)</li>
<li>스파크와 R을 연결시키고, R개발 도구인 RStudio와 연결한다.</li>
</ol>
<h3 id="스파크-하둡-플랫폼-구축-설치과정">2. 스파크-하둡 플랫폼 구축 설치과정</h3>
<h4 id="부랑자vagrant를-설치한다.">2.1. 부랑자(Vagrant)를 설치한다.</h4>
<p>가상상자(VirtualBox)와 부랑자(Vagrant)를 윈도우즈에 설치하고 나서, 명령라인 인터페이스에서 <code>vagrant init</code>을 실행시키면 <code>Vagrantfile</code> 파일이 생성된다. 텍스트 편집기를 열고 다음과 같이 미리 환경설정을 마친 리눅스 컴퓨터를 생성시킨다.</p>
<ol style="list-style-type: decimal">
<li><code>config.vm.box = &quot;ubuntu/trusty64&quot;</code> → 64비트 우분투 리눅스 가상컴퓨터 생성</li>
<li><code>config.vm.network &quot;forwarded_port&quot;, guest: 8787, host: 8787</code> → 8787포트로 나중에 RStudio를 웹인터페이스로 접속한다.</li>
<li><code>config.vm.synced_folder  &quot;C:/Users/KwangChun/rstudio&quot;, &quot;/home/vagrant/rstudio&quot;</code> → 가상컴퓨터 손님컴퓨터와 로컬 호스트 컴퓨터를 디렉토리를 서로 공유시킨다.</li>
<li><code>vb.memory = &quot;2048&quot;</code> → 가상컴퓨터 메모리를 2GB로 설정한다.</li>
</ol>
<p><code>vagrant up</code> 명령어를 실행시키면 가상컴퓨터가 구동되고, <code>vagrant ssh</code> 하면 <code>ssh</code>로 로그인하게 되고, 비번은 기본디폴트 설정으로 <code>vagrant</code>다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># -*- mode: ruby -*-</span>
<span class="co"># vi: set ft=ruby :</span>

<span class="kw">Vagrant.configure</span>(<span class="dv">2</span>) do |config|
<span class="st">  </span><span class="co"># Every Vagrant development environment requires a box. You can search for</span>
<span class="st">  </span><span class="co"># boxes at https://atlas.hashicorp.com/search.</span>
<span class="st">  </span>config.vm.box =<span class="st"> &quot;ubuntu/trusty64&quot;</span>

  config.vm.network <span class="st">&quot;forwarded_port&quot;</span>, guest:<span class="st"> </span><span class="dv">8787</span>, host:<span class="st"> </span><span class="dv">8787</span>
  config.vm.synced_folder  <span class="st">&quot;C:/Users/KwangChun/rstudio&quot;</span>, <span class="st">&quot;/home/vagrant/rstudio&quot;</span>

  config.vm.provider <span class="st">&quot;virtualbox&quot;</span> do |vb|
<span class="st">  </span><span class="co">#   vb.gui = true</span>
<span class="st">  </span>
<span class="st">  </span><span class="co"># Customize the amount of memory on the VM:</span>
<span class="st">     </span>vb.memory =<span class="st"> &quot;2048&quot;</span>
  end
end</code></pre></div>
<h4 id="자바-설치">2.2. 자바 설치</h4>
<p><a href="http://hadoop.apache.org/">아파치 하둡(Apache Hadoop)</a>이 자바를 기반으로 하기 때문에 자바 개발환경 혹은 자바를 돌릴 수 있는 가상환경을 설치해야 한다. 리눅스에 <code>openjdk</code>를 설치하여 이 문제를 해결한다. <a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">$<span class="st"> </span>sudo add-apt-repository ppa:openjdk-r/ppa
$<span class="st"> </span>sudo apt-get update
$<span class="st"> </span>sudo apt-get install openjdk<span class="dv">-8</span>-jdk</code></pre></div>
<p>또다른 방법으로 <code>webupd8team/java</code>를 사용하는 것도 가능하다.</p>
<pre class="shell"><code>$ sudo apt-add-repository ppa:webupd8team/java
$ sudo apt-get update
$ sudo apt-get install oracle-java8-installer
$ java -version</code></pre>
<p><code>java -version</code> 명령어를 통해 자바가 정상적으로 설치된 것을 확인한다.</p>
<pre class="output"><code>java version &quot;1.8.0_91&quot;
Java(TM) SE Runtime Environment (build 1.8.0_91-b14)
Java HotSpot(TM) 64-Bit Server VM (build 25.91-b14, mixed mode)</code></pre>
<p>만약 스파크를 자바를 설치하지 않고 설치할 경우 <code>JAVA_HOME is not set</code> 라는 오류가 뜨는데, 절대로 당황하지 말고, <code>openjdk</code>를 설치하면 해결된다.</p>
<pre class="error"><code>vagrant@vagrant-ubuntu-trusty-64:~/spark-1.6$ ./bin/spark-shell
JAVA_HOME is not set</code></pre>
<h4 id="스칼라-설치">2.3. 스칼라 설치</h4>
<p>최신 <a href="http://www.scala-lang.org/download/2.11.8.html">스칼라 2.11.8</a> 버젼을 다운로드한다. <code>/usr/local/src/scala</code> 디렉토리를 생성하고 다운로드 받은 스칼라 압축파일을 푼다.</p>
<pre class="shell"><code>$ wget http://downloads.lightbend.com/scala/2.11.8/scala-2.11.8.tgz
$ sudo mkdir /usr/local/src/scala
$ sudo tar xvf scala-2.11.8.tgz -C /usr/local/src/scala/</code></pre>
<p><code>.bashrc</code> 파일을 편집하여 스칼라가 설치된 디렉토리를 경로에 추가한다.</p>
<pre class="shell"><code>$ sudo gedit .bashrc
$ . .bashrc</code></pre>
<aside class="callout panel panel-info">
<div class="panel-heading">
<h4 id="bashrc-파일-추가"><span class="glyphicon glyphicon-pushpin"></span>.bashrc 파일 추가</h4>
</div>
<div class="panel-body">
<pre class="shell"><code>export SCALA_HOME=/usr/local/src/scala/scala-2.11.8
export PATH=$SCALA_HOME/bin:$PATH</code></pre>
</div>
</aside>
<pre class="shell"><code>$ scala -version
Scala code runner version 2.11.8 -- Copyright 2002-2016, LAMP/EPFL</code></pre>
<p><code>scala -version</code> 명령어로 스칼라가 정상적으로 설치된 것을 확인한다.</p>
<h4 id="하둡과-스파크-설치-hadoop-vs-spark">2.4. 하둡과 스파크 설치 <a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></h4>
<p>하둡과 스파크의 관계가 다음 <a href="http://www.infoworld.com/article/3014440/big-data/five-things-you-need-to-know-about-hadoop-v-apache-spark.html">인포월드, Five things you need to know about Hadoop v. Apache Spark</a> 기사로 잘 정리되어 있다.</p>
<table style="width:100%;">
<colgroup>
<col width="24%" />
<col width="37%" />
<col width="37%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">구분</th>
<th align="left">하둡</th>
<th align="left">스파크</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. 하둡과 스파크는 다르다</td>
<td align="left">분산 데이터 인프라</td>
<td align="left">분산된 데이터 처리 도구</td>
</tr>
<tr class="even">
<td align="left">2. 서로 필요는 없다</td>
<td align="left">HDFS와 MapReduce라는 자체 데이터 처리 도구가 포함</td>
<td align="left">하둡과 가장 잘 동작하지만, 굳이 하둡이 필요하지는 않음</td>
</tr>
<tr class="odd">
<td align="left">3. 속도</td>
<td align="left">맵리듀스를 배치방식이라 늦음</td>
<td align="left">인메모리 처리 방식이라 배치는 10배, 인메모리 분석에는 100배 빠름</td>
</tr>
<tr class="even">
<td align="left">4. 모든 작업에 속도가 중요한가</td>
<td align="left">정적이며 배치형태 작업에 적합</td>
<td align="left">실시간 IoT 센서, 기계학습, 실시간 마케팅, 온라인 추천 등에 적합</td>
</tr>
<tr class="odd">
<td align="left">5. 장애 복구 능력</td>
<td align="left">태생적으로 시스템 장애에 내성이 강함</td>
<td align="left">RDD로 장애 복구능력을 기본 제공</td>
</tr>
</tbody>
</table>
<p>하둡 스파크 설치 과정은 다음과 같다.</p>
<ol style="list-style-type: decimal">
<li>아파치 스파크 <a href="http://spark.apache.org/downloads.html">다운로드 사이트</a>에서 설치파일을 지정한다.
<ul>
<li>마우스 우클릭하여 <code>다른 이름으로 링크 저장...</code> 하여 파일 URI를 복사한다.</li>
</ul></li>
<li><code>wget</code> 명령어로 파일을 가상컴퓨터로 받아 온다.
<ul>
<li>스파크와 하둡이 모두 포함된 경우 약 300 MB 정도 크기가 나온다.</li>
</ul></li>
<li>압축을 <code>tar</code> 명령어로 풀고 나면 모든 설치가 완료된 것이다.</li>
<li><code>.\bin\spark-shell</code> 명령어를 쉘에서 입력하면 스파크 설정이 완료된 것이다.</li>
</ol>
<pre class="shell"><code>$ wget http://d3kbcqa49mib13.cloudfront.net/spark-1.6.1-bin-hadoop2.6.tgz
$ tar -xvf spark-1.6.1-bin-hadoop2.6.tgz
$ cd spark-1.6.1-bin-hadoop2.6/
$ ./bin/spark-shell</code></pre>
<pre class="output"><code>Using Spark&#39;s repl log4j profile: org/apache/spark/log4j-defaults-repl.properties
To adjust logging level use sc.setLogLevel(&quot;INFO&quot;)
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  &#39;_/
   /___/ .__/\_,_/_/ /_/\_\   version 1.6.1
      /_/

Using Scala version 2.10.5 (OpenJDK 64-Bit Server VM, Java 1.8.0_91)
Type in expressions to have them evaluated.
Type :help for more information.
Spark context available as sc.
SQL context available as sqlContext.

scala&gt;</code></pre>
<h5 id="소스코드-컴파일-설치">2.4.1. 소스코드 컴파일 설치</h5>
<p>컴파일된 스파크를 사용해도 되고 소스코드를 가지고 직접 빌드해서 스파크를 설치한다.</p>
<pre class="shell"><code>parallels@ubuntu:~$ cd spark-1.6.1/
parallels@ubuntu:~/spark-1.6.1$ sbt/sbt assembly</code></pre>
<p>스파크 소스코드가 설치된 곳으로 가서 <code>sbt/sbt assembly</code> 명령어로 실행을 하면 빌드를 시작한다. 시간이 조금 걸리는 시원한 커피를 한잔 마시고 와도 좋다.</p>
<p>스파크를 빌드하는데 SBT(Simple Build Tool)이 사용되는데 스파크에 번들로 같이 제공된다.</p>
<p>만약 가상컴퓨터 위에 우분투를 올려 컴파일하는 경우 1GB 메모리는 오류 메시지가 나니 충분히 준비하고 <code>sbt/sbt assembly</code> 명령어를 실행한다.</p>
<pre class="shell"><code>parallels@ubuntu:~/spark-1.6.1$ ./bin/run-example SparkPi 10</code></pre>
<pre class="output"><code>....
Pi is roughly 3.142296
...</code></pre>
<p>명령어를 실행시켜 스파크가 제대로 설치되었는지 확인한다. <span class="math inline">\(\pi\)</span>는 대략 3.142296 값을 출력한다.</p>
<h4 id="r-rstudio-스파크-설치">2.4. R, RStudio 스파크 설치</h4>
<h5 id="rjava-설치">2.4.1. <code>rJava</code> 설치</h5>
<p>C++와 R을 연결시켜주는 팩키지가 <code>Rcpp</code>라면, R과 자바를 연결해주는 팩키지가 <code>rJava</code>다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;rJava&quot;</span>)
<span class="kw">library</span>(rJava)</code></pre></div>
<p>R 콘솔, RStudio에서 상기 명령어가 잘 동작하지 않는 경우</p>
<ol style="list-style-type: decimal">
<li><code>sudo R CMD javareconf</code> 명령어를 쉘에서 실행하고 <code>rJava</code>를 설치한다. <a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a></li>
<li><code>sudo apt-get install r-cran-rjava</code> R과 자바를 문제없이 연결시킨 <code>r-cran-rjava</code>를 설치한다. <a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a></li>
</ol>
<h4 id="sparkr-팩키지-r-적재">2.4.2. <code>SparkR</code> 팩키지 R 적재</h4>
<p><code>SparkR</code> 라이브러리를 스파크가 설치된 디렉토리를 지정해서 적재시킨다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(SparkR, <span class="dt">lib.loc =</span> <span class="st">&quot;/home/vagrant/spark-1.6/R/lib/&quot;</span>)</code></pre></div>
<pre class="output"><code>Attaching package: ‘SparkR’

The following objects are masked from ‘package:stats’:

    cov, filter, lag, na.omit, predict, sd, var

The following objects are masked from ‘package:base’:

    colnames, colnames&lt;-, endsWith, intersect, rank, rbind, sample, startsWith,
    subset, summary, table, transform</code></pre>
<h4 id="sparkr-헬로월드-sparkr-rstudio">2.4.3. <code>SparkR</code> 헬로월드 <a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a></h4>
<p><code>sparkHome</code> 홈디렉토리를 지정하여 <code>sc</code> 객체로 지정한다. <code>sparkRSQL.init</code>로 SQL 초기화를 하고 나서 <code>createDataFrame</code> 데이터프레임을 지정한다.</p>
<p>이제 데이터프레임으로 R로 넘어왔기 때문에 <code>sparkDf</code> 데이터프레임으로 다양한 통계분석을 수행하면 된다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sc &lt;-<span class="st"> </span><span class="kw">sparkR.init</span>(<span class="dt">sparkHome =</span> <span class="st">&quot;/home/vagrant/spark-1.6/&quot;</span>)
sqlContext &lt;-<span class="st"> </span><span class="kw">sparkRSQL.init</span>(sc)
SparkDf &lt;-<span class="st"> </span><span class="kw">createDataFrame</span>(sqlContext,faithful)
<span class="kw">head</span>(SparkDf)</code></pre></div>
<pre class="output"><code>  eruptions waiting
1     3.600      79
2     1.800      54
3     3.333      74
4     2.283      62
5     4.533      85
6     2.883      55</code></pre>
<p><img src="fig/sparkR-setup-screen.png" alt="sparkR 설치 화면" width="77%"></p>
<h3 id="맥-운영체제-mac-sparkr-install">3. 맥 운영체제 <a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a></h3>
<p>맥(OS X)에서 SparkR을 설치하는 것은 단 6줄로 간단히 처리할 수 있다.</p>
<ol style="list-style-type: decimal">
<li>만약 자바가 설치되지 않은 경우, 자바를 설치한다.</li>
<li>하둡을 설치한다.</li>
<li>아파치-스파크를 설치한다.</li>
<li>RStudio 에서 SparkR을 설정한다.</li>
</ol>
<pre class="shell"><code>$ brew install Caskroom/cask/java
$ brew install hadoop
$ brew install apache-spark
$ SparkR</code></pre>
<pre class="output"><code>parallel-r $ SparkR

R version 3.2.4 (2016-03-10) -- &quot;Very Secure Dishes&quot;
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin13.4.0 (64-bit)

R은 자유 소프트웨어이며, 어떠한 형태의 보증없이 배포됩니다.
또한, 일정한 조건하에서 이것을 재배포 할 수 있습니다.
배포와 관련된 상세한 내용은 &#39;license()&#39; 또는 &#39;licence()&#39;을 통하여 확인할 수 있습니다.

R은 많은 기여자들이 참여하는 공동프로젝트입니다.
&#39;contributors()&#39;라고 입력하시면 이에 대한 더 많은 정보를 확인하실 수 있습니다.
그리고, R 또는 R 패키지들을 출판물에 인용하는 방법에 대해서는 &#39;citation()&#39;을 통해 확인하시길 부탁드립니다.

&#39;demo()&#39;를 입력하신다면 몇가지 데모를 보실 수 있으며, &#39;help()&#39;를 입력하시면 온라인 도움말을 이용하실 수 있습니다.
또한, &#39;help.start()&#39;의 입력을 통하여 HTML 브라우저에 의한 도움말을 사용하실수 있습니다
R의 종료를 원하시면 &#39;q()&#39;을 입력해주세요.

Launching java with spark-submit command /usr/local/Cellar/apache-spark/1.6.0/libexec/bin/spark-submit   &quot;sparkr-shell&quot; /var/folders/g3/97168ry52ll6zfyl6ykyk3br0000gn/T//Rtmp6KjqqH/backend_port136f6e14d4f5 
log4j:WARN No appenders could be found for logger (io.netty.util.internal.logging.InternalLoggerFactory).
....
....
16/06/06 14:50:12 INFO BlockManagerMaster: Registered BlockManager

 Welcome to
    ____              __ 
   / __/__  ___ _____/ /__ 
  _\ \/ _ \/ _ `/ __/  &#39;_/ 
 /___/ .__/\_,_/_/ /_/\_\   version  1.6.0 
    /_/ 


 Spark context is available as sc, SQL context is available as sqlContext
 &gt; </code></pre>
<p>RStudio에서 SparkR을 실행할 경우 다음과 명령어를 실행한다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## 스파크가 설치된 환경정보를 받아온다.
spark_path &lt;-<span class="st"> </span><span class="kw">strsplit</span>(<span class="kw">system</span>(<span class="st">&quot;brew info apache-spark&quot;</span>,<span class="dt">intern=</span>T)[<span class="dv">4</span>],<span class="st">&#39; &#39;</span>)[[<span class="dv">1</span>]][<span class="dv">1</span>] 

## SparkR 라이브러리 디렉토리를 지정한다.
<span class="kw">.libPaths</span>(<span class="kw">c</span>(<span class="kw">file.path</span>(spark_path,<span class="st">&quot;libexec&quot;</span>, <span class="st">&quot;R&quot;</span>, <span class="st">&quot;lib&quot;</span>), <span class="kw">.libPaths</span>())) 

## SparkR 라이브러리를 적재한다.
<span class="kw">library</span>(SparkR)

sc &lt;-<span class="st"> </span><span class="kw">sparkR.init</span>()
sqlContext &lt;-<span class="st"> </span><span class="kw">sparkRSQL.init</span>(sc)
df &lt;-<span class="st"> </span><span class="kw">createDataFrame</span>(sqlContext, iris) 
<span class="kw">head</span>(df)</code></pre></div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p><a href="http://blog.prabeeshk.com/blog/2014/10/31/install-apache-spark-on-ubuntu-14-dot-04/">Install Apache Spark on Ubuntu-14.04</a><a href="#fnref1">↩</a></p></li>
<li id="fn2"><p><a href="http://askubuntu.com/questions/464755/how-to-install-openjdk-8-on-14-04-lts">How to install OpenJDK 8 on 14.04 LTS?</a><a href="#fnref2">↩</a></p></li>
<li id="fn3"><p><a href="https://www.quora.com/What-is-the-difference-between-Apache-Spark-and-Apache-Hadoop-Map-Reduce">What is the difference between Apache Spark and Apache Hadoop (Map-Reduce)?</a><a href="#fnref3">↩</a></p></li>
<li id="fn4"><p><a href="http://stackoverflow.com/questions/30572258/error-of-java-path-on-loading-rjava-package">Error of java path on loading rJava package</a><a href="#fnref4">↩</a></p></li>
<li id="fn5"><p><a href="http://stackoverflow.com/questions/3311940/r-rjava-package-install-failing">R: rJava package install failing</a><a href="#fnref5">↩</a></p></li>
<li id="fn6"><p><a href="http://www.r-bloggers.com/sparkr-with-rstudio-in-ubuntu-12-04/">SparkR with Rstudio in Ubuntu 12.04</a><a href="#fnref6">↩</a></p></li>
<li id="fn7"><p><a href="http://www.r-bloggers.com/six-lines-to-install-and-start-sparkr-on-mac-os-x-yosemite/">Six lines to install and start SparkR on Mac OS X Yosemite</a><a href="#fnref7">↩</a></p></li>
</ol>
</div>
        </div>
      </div>
      </article>
      <div class="footer">
        <a class="label swc-blue-bg" href="http://software-carpentry.org">Software Carpentry</a>
        <a class="label swc-blue-bg" href="https://github.com/swcarpentry/lesson-template">Source</a>
        <a class="label swc-blue-bg" href="mailto:admin@software-carpentry.org">Contact</a>
        <a class="label swc-blue-bg" href="LICENSE.html">License</a>
      </div>
    </div>
    <!-- Javascript placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
    <script src="css/bootstrap/bootstrap-js/bootstrap.js"></script>
    <script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    
      ga('create', 'UA-37305346-2', 'auto');
      ga('send', 'pageview');
    
    </script>
  </body>
</html>
