---
layout: page
subtitle: sparklyr 추천시스템 - MovieLens, One Million Songs
date: "`r Sys.Date()`"
author: xwMOOC
output:
  html_document: 
    toc: yes
    toc_float: true
    highlight: tango
    code_folding: show
    number_section: true
    self_contained: true
    lib_dir: gapminder
editor_options: 
  chunk_output_type: console
---
 

``` {r, include=FALSE}
# source("tools/chunk-options.R")

knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE,
                    comment="", digits = 3, tidy = FALSE, prompt = TRUE, fig.align = 'center')

options(scipen=999)
```


# `MovieLens` 데이터 [^movielens-data] [^recommendation-system-theory] {#movielens-dataset}

[^movielens-data]: ["How to Build A Recommender System In Less Than 1 Hour"](http://blog.avenuecode.com/how-to-build-a-recommender-system-in-less-than-1-hour)

[^recommendation-system-theory]: [Dmitriy Selivanov, Data Scientist(Nov 19, 2017), "Matrix Factorizations for Recommender Systems"](https://www.slideshare.net/DmitriySelivanov/matrix-factorizations-for-recommender-systems)

[MovieLens 1M Dataset](https://grouplens.org/datasets/movielens/1m/) 데이터를 다운로드 받아 이를 정제하는 것부터 시작한다.

## 데이터 가져오기 {#movielens-dataset-download}

[MovieLens 1M Dataset](https://grouplens.org/datasets/movielens/1m/) 데이터를 다운로드 받아 압축을 풀고, 
`ml-1m` 디렉토리 `movies.dat`, `ratings.dat`, `users.dat`를 대상으로 작업을 준비한다.

```{r movielens-dataset-downlaod}
library(here)
# download.file(url="http://files.grouplens.org/datasets/movielens/ml-1m.zip", destfile="data/ml-1m.zip")
unzip_file <- here("data", "ml-1m.zip")

unzip(zipfile = unzip_file, exdir="data/raw")
```



## `MovieLens` 데이터 정제 [^movielens-clean]

[^movielens-clean]: [Exploratory analysis of Movie preference data set](https://github.com/statkclee/STAT545A_MovieStats/blob/master/cleanMovieLensData.R)

평점, 사용자, 영화 아이템 파일을 순차로 R 데이터프레임으로 불러와서 데이터를 정제한다.
특히, `read_delim()` 함수 등 `readr` 팩키지에서는 구분자가 두문자 이상인 경우 지원을 하지 않기 때문에 
[Multicharacter separator/deliminator in Read_delim of Tidyverse? #721](https://github.com/tidyverse/readr/issues/721) 내용을 참조해서,
구분문자를 `::`에서 탭(`\t`)으로 바꾼 후에 다시 `read_delim()` 함수로 불러온다.

```{r movielens-dataset-clean}
library(tidyverse)
## movies.dat --> https://github.com/tidyverse/readr/issues/721
movie_txt <- read_lines("data/raw/ml-1m/movies.dat")
movie_txt <- str_replace_all(movie_txt, "::", "\t")
movie_txt %>% write_lines("data/raw/ml-1m/movies.txt")
movie_df  <- read_delim("data/raw/ml-1m/movies.txt", delim="\t", col_names = FALSE)

## ratings.dat
rating_txt <- read_lines("data/raw/ml-1m/ratings.dat")
rating_txt <- str_replace_all(rating_txt, "::", "\t")
rating_txt %>% write_lines("data/raw/ml-1m/ratings.txt")
rating_df  <- read_delim("data/raw/ml-1m/ratings.txt", delim="\t", col_names = FALSE)

## users.dat
user_txt <- read_lines("data/raw/ml-1m/users.dat")
user_txt <- str_replace_all(user_txt, "::", "\t")
user_txt %>% write_lines("data/raw/ml-1m/users.txt")
user_df  <- read_delim("data/raw/ml-1m/users.txt", delim="\t", col_names = FALSE)

rm(list = ls(pattern = "txt$"))
```


```{r movielens-dataset-clean-merge}
movie_df <- movie_df %>% 
    rename(movie_id = X1,
           movie_nm = X2,
           genre = X3)

rating_df <- rating_df %>% 
    rename(user_id = X1,
           movie_id = X2,
           rating = X3,
           timestamp = X4)

user_df <- user_df %>% 
    rename(user_id = X1,
           gender = X2,
           age = X3,
           occupation = X4,
           zipcode = X5)

um_rating_df <- user_df %>% select(user_id) %>% 
    left_join(rating_df, by="user_id") %>% 
    select(-timestamp) %>% 
    left_join(movie_df, by="movie_id") 

um_rating_df %>% 
    sample_n(100) %>% 
    DT::datatable()

```

# `sparklyr` 맛보기 [^install-sparklyr] {#movielens-sparkly}

[^install-sparklyr]: [RStudio, sparklyr: R interface for Apache Spark](http://spark.rstudio.com/)

## 스파크 클러스터 생성 {#movielens-sparkly-cluster}

[RStudio, sparklyr: R interface for Apache Spark](http://spark.rstudio.com/)를 참조하여 자바를 설치하지 않았다면 설치하고 나서
`sparklyr`을 통해 스파크 클러스터를 생성하여 작업을 추진하도록 한다.

```{r movielens-sparklyr-cluster}
library(sparklyr)
sc <- spark_connect(master = "local")
spark_version(sc)
```

## 스파크 클러스터 데이터 올리기 {#movielens-sparkly-cluster-loading}

R 데이터프레임(`um_rating_df`)을 스파크 데이터프레임으로 변환시킨다.

```{r movielens-sparklyr-cluster-load}
um_rating_sdf <- sdf_copy_to(sc, um_rating_df, "um_rating", overwrite = TRUE)
src_tbls(sc)
```

## ALS 모형적합 {#movielens-sparkly-cluster-loading-fit}

ALS 알고리즘을 실행시켜 평점 행렬을 분해한다.

```{r movielens-sparklyr-cluster-load-mf}
library(dplyr)

partitions <- sdf_partition(um_rating_sdf, training = 0.8, test = 0.2)

movie_als <- ml_als_factorization(partitions$training, 
                                  rating.column = "rating", 
                                  user.column = "user_id", 
                                  item.column = "movie_id", 
                                  rank = 10L,
                                  regularization.parameter = 0.1,
                                  implicit.preferences = FALSE,
                                  alpha =1,
                                  nonnegative = TRUE,
                                  iter.max = 10)
summary(movie_als)
```


## 평점 예측 {#movielens-sparkly-cluster-loading-fit}

ALS 알고리즘을 실행시켜 평점 행렬을 분해한다.
```{r movielens-sparklyr-cluster-load-mf-predict}
predictions <- ml_predict(movie_als, partitions$test)

movie_pred_df <- predictions %>% collect() %>% 
    filter(complete.cases(.))

movie_pred_df %>% 
    head()

library(Metrics)
rmse(movie_pred_df$prediction, movie_pred_df$rating)

spark_disconnect(sc)
```



